{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open existed training set\n",
    "with open(\"./data/X_train.p\", \"rb\") as f:\n",
    "    Xtrain = pickle.load(f)\n",
    "\n",
    "# open existed training set\n",
    "with open(\"./data/y_train.p\", \"rb\") as f:\n",
    "    ytrain = pickle.load(f)\n",
    "    \n",
    "# open existed test set\n",
    "with open(\"./data/X_test.p\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 32000\n",
    "n_validation = 10000\n",
    "\n",
    "X_train = Xtrain[:n_train]\n",
    "X_validation = Xtrain[n_train:n_train+n_validation]\n",
    "\n",
    "y_train = ytrain[:n_train]\n",
    "y_validation = ytrain[n_train:n_train+n_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (n_train, 28,28,1))\n",
    "X_validation = np.reshape(X_validation, (n_validation, 28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (28000, 28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_validation = X_validation/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle the training set\n",
    "# X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building CNN Model\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 28x28x1. Output = 24x24x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # Pooling. Input = 24x24x6. Output = 12x12x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolutional. Output = 8x8x22.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 22), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(22))\n",
    "    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # Pooling. Input = 8x8x22. Output = 4x4x22.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Flatten. Input = 4x4x22. Output = 352.\n",
    "    fc0 = flatten(conv2)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 352. Output = 100.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(352, 100), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(100))\n",
    "    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    # Layer 4: Fully Connected. Input = 100. Output = 40.\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(100, 40), mean = mu, stddev = sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(40))\n",
    "    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 40. Output = 10.\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(40, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=(None,28,28,1), name=\"x\")\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None), name=\"y\")\n",
    "one_hot_y = tf.one_hot(y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = LeNet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_min(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "# #     sess.run(logits, feed_dict={x: X_train})\n",
    "#     sess.run(training_operation, feed_dict={x: X_train, y:y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.105\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3fdf97ca95ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#             print(\"from \", offset, \"to\", end)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#             print(batch_x.shape, batch_y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mvalidation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Start training ...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        loss_summ = 0\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "#             print(\"from \", offset, \"to\", end)\n",
    "#             print(batch_x.shape, batch_y.shape)\n",
    "            l = sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            loss_summ = loss_summ + l\n",
    "            \n",
    "        \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"loss:\", loss_summ)\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, model_folder + \"/trained_model.ckpt\")\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 28, 28, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.reshape(X_train[0], (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2240d2a6940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlist = []\n",
    "xlist.append(X_train[0])\n",
    "\n",
    "ylist = []\n",
    "ylist.append(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\trained_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\trained_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Load trained model\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\"./model\"))\n",
    "    test_logits = sess.run(logits, feed_dict={x: xlist, y: ylist})\n",
    "    prediction = tf.argmax(test_logits, 1)\n",
    "    \n",
    "#     print(\"predictions\", prediction.eval(feed_dict={x: xlist}, session=sess))\n",
    "#     print(\"true values\",y_web_test)\n",
    "    print(sess.run(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax_4:0' shape=(1,) dtype=int64>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "mu = 0\n",
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1: Convolutional. Input = 28x28x1. Output = 24x24x6.\n",
    "conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "conv1_b = tf.Variable(tf.zeros(6))\n",
    "conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "# Activation.\n",
    "conv1 = tf.nn.relu(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling. Input = 24x24x6. Output = 12x12x6.\n",
    "conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 2: Convolutional. Output = 8x8x22.\n",
    "conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 22), mean = mu, stddev = sigma))\n",
    "conv2_b = tf.Variable(tf.zeros(22))\n",
    "conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "\n",
    "# Activation.\n",
    "conv2 = tf.nn.relu(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "fc0 = flatten(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten. Input = 3x3x22. Output = 198.\n",
    "fc0 = flatten(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 3: Fully Connected. Input = 198. Output = 100.\n",
    "fc1_W = tf.Variable(tf.truncated_normal(shape=(198, 100), mean = mu, stddev = sigma))\n",
    "fc1_b = tf.Variable(tf.zeros(100))\n",
    "fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "\n",
    "# Activation.\n",
    "fc1 = tf.nn.relu(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
